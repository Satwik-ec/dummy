#!/usr/bin/env python3
from __future__ import annotations

import argparse
import datetime as dt
import re
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Tuple, Dict

from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side


# ---------- Parsing patterns ----------
DB_OK_STR = "database successfully generated"
ERR_PATTERN = re.compile(r"Error-\[", re.IGNORECASE)  # '[' must be escaped
UVM_ERR_PATTERN = re.compile(r"\bUVM_ERROR\b")
UVM_FATAL_PATTERN = re.compile(r"\bUVM_FATAL\b")


@dataclass
class CompileResult:
    lp: str
    status: str              # PASS/FAIL/NA
    log_path: Optional[Path]
    errors: List[str]
    chosen_dir: Optional[str]


@dataclass
class TestResult:
    test_dir: str
    status: str              # PASS/FAIL/RUNNING/UNKNOWN
    uvm_messages: List[str]  # actual lines (only meaningful when completed/failed)
    log_path: Optional[Path]


# ----------------- Log helpers -----------------
def safe_read_lines(log_path: Path, max_bytes: int = 10_000_000) -> List[str]:
    try:
        with log_path.open("rb") as f:
            data = f.read(max_bytes + 1)
        if len(data) > max_bytes:
            data = data[:max_bytes]
        return data.decode(errors="replace").splitlines()
    except (FileNotFoundError, OSError):
        return []


def second_last_nonempty_line_contains(lines: List[str], needle: str) -> bool:
    trimmed = [l for l in lines if l.strip()]
    if not trimmed:
        return False
    if len(trimmed) < 2:
        return needle in trimmed[-1]
    return needle in trimmed[-2]


def extract_compile_errors(lines: List[str], max_lines: int = 30) -> List[str]:
    errs = [l.strip() for l in lines if ERR_PATTERN.search(l)]
    seen = set()
    uniq: List[str] = []
    for e in errs:
        if e not in seen:
            uniq.append(e)
            seen.add(e)
        if len(uniq) >= max_lines:
            break
    return uniq


def extract_uvm_messages(lines: List[str], max_lines: int = 50) -> List[str]:
    msgs: List[str] = []
    for line in lines:
        if "UVM_ERROR" in line or "UVM_FATAL" in line:
            msgs.append(line.strip())
        if len(msgs) >= max_lines:
            break
    return msgs


# ----------------- Discover regression structure -----------------
def discover_configs(reg_root: Path) -> List[Path]:
    """
    Config dirs:
    - immediate subdirs under regression root
    - dir name contains 'uio'
    - contains sim/
    """
    if not reg_root.is_dir():
        return []
    configs = []
    for p in reg_root.iterdir():
        if p.is_dir() and ("uio" in p.name.lower()) and (p / "sim").is_dir():
            configs.append(p)
    return sorted(configs, key=lambda x: x.name)


def find_compile_dirs(sim_dir: Path) -> List[Path]:
    if not sim_dir.is_dir():
        return []
    return [p for p in sim_dir.iterdir() if p.is_dir() and p.name.startswith("compile_dw_")]


def classify_lp_from_dirname(name: str) -> Optional[str]:
    n = name.lower()
    if "vdut" in n:
        return "VDUT"
    if "vip" in n:
        return "VIP"
    return None


def pick_newest(paths: List[Path]) -> Optional[Path]:
    return max(paths, key=lambda p: p.stat().st_mtime) if paths else None


def compile_status_for_lp(sim_dir: Path, lp: str) -> CompileResult:
    compile_dirs = find_compile_dirs(sim_dir)
    candidates = [d for d in compile_dirs if classify_lp_from_dirname(d.name) == lp]
    chosen = pick_newest(candidates)

    if chosen is None:
        return CompileResult(lp=lp, status="NA", log_path=None, errors=[], chosen_dir=None)

    log_path = chosen / "test.log"
    lines = safe_read_lines(log_path)

    if second_last_nonempty_line_contains(lines, DB_OK_STR):
        return CompileResult(lp=lp, status="PASS",
                             log_path=log_path if log_path.exists() else None,
                             errors=[], chosen_dir=chosen.name)

    errs = extract_compile_errors(lines)
    return CompileResult(lp=lp, status="FAIL",
                         log_path=log_path if log_path.exists() else None,
                         errors=errs, chosen_dir=chosen.name)


def find_test_dirs(sim_dir: Path) -> List[Path]:
    """
    Test dirs:
    - under sim/
    - not starting with compile_dw_
    - contains 'vtb' in name
    """
    if not sim_dir.is_dir():
        return []
    out = []
    for p in sim_dir.iterdir():
        if not p.is_dir():
            continue
        if p.name.startswith("compile_dw_"):
            continue
        if "vtb" not in p.name.lower():
            continue
        out.append(p)
    return sorted(out, key=lambda x: x.name)


def get_test_state_from_markers(test_dir: Path) -> str:
    """
    Your rule:
      - if passed exists => PASS
      - if failed exists => FAIL
      - else if compile_passed exists => RUNNING
      - else => UNKNOWN
    """
    if (test_dir / "passed").exists():
        return "PASS"
    if (test_dir / "failed").exists():
        return "FAIL"
    if (test_dir / "compile_passed").exists():
        return "RUNNING"
    return "UNKNOWN"


def parse_test_results(sim_dir: Path) -> List[TestResult]:
    results: List[TestResult] = []
    for tdir in find_test_dirs(sim_dir):
        state = get_test_state_from_markers(tdir)
        log_path = tdir / "test.log"

        # Only extract UVM lines when:
        # - FAIL (most useful)
        # - or PASS (optional, but typically none)
        # For RUNNING/UNKNOWN we avoid misclassifying.
        msgs: List[str] = []
        if state in ("FAIL", "PASS") and log_path.exists():
            lines = safe_read_lines(log_path)
            msgs = extract_uvm_messages(lines)

        results.append(TestResult(
            test_dir=tdir.name,
            status=state,
            uvm_messages=msgs,
            log_path=log_path if log_path.exists() else None,
        ))
    return results


def is_config_compile_clean(vdut: CompileResult, vip: CompileResult) -> bool:
    return (vdut.status == "PASS") and (vip.status == "PASS")


# ----------------- Cell builders (Todays Date cell contains date + details) -----------------
def build_compilation_cell(today: str, comp: CompileResult) -> str:
    lines: List[str] = [today, f"Compilation: {comp.status}"]

    info = []
    if comp.chosen_dir:
        info.append(f"dir={comp.chosen_dir}")
    if comp.log_path:
        info.append(f"log={comp.log_path}")
    if info:
        lines.append("Info: " + ", ".join(info))

    if comp.status == "FAIL":
        if comp.errors:
            lines.append("Errors:")
            for i, e in enumerate(comp.errors[:10], start=1):
                lines.append(f"  {i}) {e}")
        else:
            lines.append("Errors: (no Error-[ lines found)")
    return "\n".join(lines)


def build_run_cell(today: str, tests: List[TestResult], compile_clean: bool) -> str:
    """
    Single cell content:
      <date>
      Run Summary: TOTAL=.. PASS=.. FAIL=.. RUNNING=.. UNKNOWN=..
      Failures:
        1) test_xxx
            1. UVM_ERROR ...
      Running:
        1) test_yyy
    """
    if not compile_clean:
        return "\n".join([today, "Run Summary: SKIPPED (compile not clean)"])

    total = len(tests)
    pass_cnt = sum(1 for t in tests if t.status == "PASS")
    fail_cnt = sum(1 for t in tests if t.status == "FAIL")
    run_cnt = sum(1 for t in tests if t.status == "RUNNING")
    unk_cnt = sum(1 for t in tests if t.status == "UNKNOWN")

    lines: List[str] = [
        today,
        f"Run Summary: TOTAL={total} PASS={pass_cnt} FAIL={fail_cnt} RUNNING={run_cnt} UNKNOWN={unk_cnt}"
    ]

    # Failures details with numbered UVM lines
    failing = [t for t in tests if t.status == "FAIL"]
    if failing:
        lines.append("Failures:")
        for i, t in enumerate(failing, start=1):
            lines.append(f"{i}) {t.test_dir} (log={t.log_path if t.log_path else 'NA'})")
            if t.uvm_messages:
                for j, msg in enumerate(t.uvm_messages, start=1):
                    lines.append(f"    {j}. {msg}")
            else:
                lines.append("    1. (No UVM_ERROR/UVM_FATAL lines found)")

    # Running tests list
    running = [t for t in tests if t.status == "RUNNING"]
    if running:
        lines.append("Running:")
        for i, t in enumerate(running, start=1):
            lines.append(f"{i}) {t.test_dir}")

    # Unknown tests list
    unknown = [t for t in tests if t.status == "UNKNOWN"]
    if unknown:
        lines.append("Unknown:")
        for i, t in enumerate(unknown, start=1):
            lines.append(f"{i}) {t.test_dir}")

    return "\n".join(lines)


# ----------------- Excel writer -----------------
def write_excel(out_path: Path, configs_data: Dict[str, Dict]) -> None:
    wb = Workbook()
    ws = wb.active
    ws.title = "Summary"

    header_font = Font(bold=True)
    center = Alignment(vertical="center", horizontal="center", wrap_text=True)
    left_top = Alignment(vertical="top", horizontal="left", wrap_text=True)

    thin = Side(style="thin")
    border = Border(left=thin, right=thin, top=thin, bottom=thin)

    pass_fill = PatternFill("solid", fgColor="C6EFCE")
    fail_fill = PatternFill("solid", fgColor="FFC7CE")
    na_fill = PatternFill("solid", fgColor="E7E6E6")
    run_fill = PatternFill("solid", fgColor="FFF2CC")  # light yellow for RUNNING

    def fill_for_cell_text(cell_text: str) -> PatternFill:
        t = (cell_text or "").upper()
        if "COMPILATION: FAIL" in t:
            return fail_fill
        if "RUN SUMMARY:" in t and " FAIL=0" in t and "RUNNING=0" in t and "UNKNOWN=0" in t:
            return pass_fill
        if "FAILURES:" in t:
            return fail_fill
        if "RUNNING=" in t and "RUNNING=0" not in t:
            return run_fill
        if "SKIPPED" in t or "UNKNOWN" in t or " NA" in t:
            return na_fill
        if "COMPILATION: PASS" in t:
            return pass_fill
        return na_fill

    ws.append(["CONFIG NAME", "LP", "Status", "Todays Date"])
    for c in range(1, 5):
        cell = ws.cell(row=1, column=c)
        cell.font = header_font
        cell.alignment = center
        cell.border = border

    row = 2
    for cfg_name in sorted(configs_data.keys()):
        cfg_start = row

        for lp in ["VDUT", "VIP"]:
            lp_start = row

            comp_text = configs_data[cfg_name]["comp_cells"][lp]
            ws.append([cfg_name, lp, "Compilation Status", comp_text])
            ws.cell(row=row, column=4).fill = fill_for_cell_text(comp_text)
            row += 1

            run_text = configs_data[cfg_name]["run_cells"][lp]
            ws.append(["", "", "Run Results", run_text])
            ws.cell(row=row, column=4).fill = fill_for_cell_text(run_text)
            row += 1

            ws.merge_cells(start_row=lp_start, start_column=2, end_row=row - 1, end_column=2)

        ws.merge_cells(start_row=cfg_start, start_column=1, end_row=row - 1, end_column=1)

        ws.append(["", "", "", ""])
        row += 1

    for r in range(1, ws.max_row + 1):
        for c in range(1, 5):
            cell = ws.cell(row=r, column=c)
            cell.border = border
            if r == 1:
                continue
            cell.alignment = center if c in (1, 2, 3) else left_top

    ws.column_dimensions["A"].width = 26
    ws.column_dimensions["B"].width = 10
    ws.column_dimensions["C"].width = 22
    ws.column_dimensions["D"].width = 95

    out_path.parent.mkdir(parents=True, exist_ok=True)
    wb.save(out_path)


def main() -> None:
    ap = argparse.ArgumentParser(description="Generate Excel summary (detect RUNNING using marker files).")
    ap.add_argument("regression_path", help="Regression root directory path")
    ap.add_argument("-o", "--out", default=None,
                    help="Output Excel file path (default: <regression_path>/regression_summary.xlsx)")
    args = ap.parse_args()

    reg_root = Path(args.regression_path).resolve()
    out_path = Path(args.out).resolve() if args.out else (reg_root / "regression_summary.xlsx")
    today = dt.date.today().isoformat()

    configs = discover_configs(reg_root)
    if not configs:
        raise SystemExit(
            f"No config dirs found under {reg_root}. Expected subdirs containing 'uio' and having sim/."
        )

    configs_data: Dict[str, Dict] = {}

    for cfg_dir in configs:
        cfg_name = cfg_dir.name
        sim_dir = cfg_dir / "sim"

        vdut_comp = compile_status_for_lp(sim_dir, "VDUT")
        vip_comp = compile_status_for_lp(sim_dir, "VIP")
        clean = is_config_compile_clean(vdut_comp, vip_comp)

        tests = parse_test_results(sim_dir) if clean else []

        comp_cells = {
            "VDUT": build_compilation_cell(today, vdut_comp),
            "VIP": build_compilation_cell(today, vip_comp),
        }
        run_cells = {
            "VDUT": build_run_cell(today, tests, clean),
            "VIP": build_run_cell(today, tests, clean),
        }

        configs_data[cfg_name] = {"comp_cells": comp_cells, "run_cells": run_cells}

    write_excel(out_path, configs_data)
    print(f"Excel report generated: {out_path}")
    print(f"Configs detected: {len(configs)}")


if __name__ == "__main__":
    main()
