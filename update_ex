#!/usr/bin/env python3
"""
PCIe Regression Summary -> Excel (formatted like screenshot)

Detection rules (as per your latest requirements):
- Config directory can be anything, but config dir name contains 'uio' (case-insensitive)
- Config dir must have <config>/sim/
- Under <config>/sim/:
  - compile directories begin with 'compile_dw_'
    - VDUT compile dir contains 'vdut' in dir name
    - VIP  compile dir contains 'vip'  in dir name
    - compile result: <compile_dir>/test.log
        PASS if second-last non-empty line contains: "database successfully generated"
        FAIL otherwise; extract errors by matching "Error-["
  - if BOTH VDUT and VIP compile PASS => run starts
  - test directories:
      - not starting with 'compile_dw_'
      - name contains 'vtb' (case-insensitive)
      - each has test.log
      - FAIL if log contains UVM_ERROR or UVM_FATAL (counted); else PASS

Excel output layout (matches screenshot):
CONFIG NAME | LP  | Compilation/Run status | Todays Date
-------------------------------------------------------
cfgX        |VDUT | Compilation Status : PASS/FAIL ...
           |     | Run Results : TOTAL=.. PASS=.. FAIL=.. (and optionally per-test)
           |VIP  | Compilation Status : ...
           |     | Run Results : ...

Usage:
  python3 regress_summary_excel_uio.py /path/to/regression
  python3 regress_summary_excel_uio.py /path/to/regression -o /path/to/out.xlsx
  python3 regress_summary_excel_uio.py /path/to/regression --no-per-test
"""

from __future__ import annotations

import argparse
import datetime as dt
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# ---------- Parsing patterns ----------
DB_OK_STR = "database successfully generated"

# IMPORTANT: '[' must be escaped, else "unterminated character set"
ERR_PATTERN = re.compile(r"Error-\[", re.IGNORECASE)

UVM_ERR_PATTERN = re.compile(r"\bUVM_ERROR\b")
UVM_FATAL_PATTERN = re.compile(r"\bUVM_FATAL\b")

# ---------- Excel ----------
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side


@dataclass
class CompileResult:
    lp: str                 # "VDUT" or "VIP"
    status: str             # "PASS" / "FAIL" / "NA"
    log_path: Optional[Path]
    errors: List[str]
    chosen_dir: Optional[str]


@dataclass
class TestResult:
    test_dir: str
    status: str             # PASS/FAIL
    uvm_error_count: int
    uvm_fatal_count: int
    log_path: Optional[Path]


# ----------------- Helpers: file/log parsing -----------------
def safe_read_lines(log_path: Path, max_bytes: int = 10_000_000) -> List[str]:
    """Read log file safely with max size cap."""
    try:
        with log_path.open("rb") as f:
            data = f.read(max_bytes + 1)
        if len(data) > max_bytes:
            data = data[:max_bytes]
        return data.decode(errors="replace").splitlines()
    except (FileNotFoundError, OSError):
        return []


def second_last_nonempty_line_contains(lines: List[str], needle: str) -> bool:
    """Return True if the second-last non-empty line contains needle."""
    trimmed = [l for l in lines if l.strip()]
    if not trimmed:
        return False
    if len(trimmed) < 2:
        return needle in trimmed[-1]
    return needle in trimmed[-2]


def extract_compile_errors(lines: List[str], max_lines: int = 30) -> List[str]:
    """Extract unique error lines matching Error-[ pattern."""
    errs = [l.strip() for l in lines if ERR_PATTERN.search(l)]
    seen = set()
    uniq: List[str] = []
    for e in errs:
        if e not in seen:
            uniq.append(e)
            seen.add(e)
        if len(uniq) >= max_lines:
            break
    return uniq


def count_uvm(lines: List[str]) -> Tuple[int, int]:
    """Count UVM_ERROR and UVM_FATAL occurrences."""
    err_cnt = sum(1 for l in lines if UVM_ERR_PATTERN.search(l))
    fatal_cnt = sum(1 for l in lines if UVM_FATAL_PATTERN.search(l))
    return err_cnt, fatal_cnt


# ----------------- Discover regression structure -----------------
def discover_configs(reg_root: Path) -> List[Path]:
    """
    Config dirs:
      - immediate subdirs under regression root
      - name contains 'uio'
      - has sim/ directory
    """
    if not reg_root.is_dir():
        return []
    configs: List[Path] = []
    for p in reg_root.iterdir():
        if p.is_dir() and ("uio" in p.name.lower()) and (p / "sim").is_dir():
            configs.append(p)
    return sorted(configs, key=lambda x: x.name)


def find_compile_dirs(sim_dir: Path) -> List[Path]:
    """Compile directories always start with compile_dw_."""
    if not sim_dir.is_dir():
        return []
    return [p for p in sim_dir.iterdir() if p.is_dir() and p.name.startswith("compile_dw_")]


def classify_lp_from_dirname(name: str) -> Optional[str]:
    n = name.lower()
    if "vdut" in n:
        return "VDUT"
    if "vip" in n:
        return "VIP"
    return None


def pick_newest(paths: List[Path]) -> Optional[Path]:
    return max(paths, key=lambda p: p.stat().st_mtime) if paths else None


def compile_status_for_lp(sim_dir: Path, lp: str) -> CompileResult:
    """
    For a given LP (VDUT/VIP), pick newest compile_dw_* dir that matches LP substring,
    and decide PASS/FAIL by test.log.
    """
    compile_dirs = find_compile_dirs(sim_dir)
    candidates = [d for d in compile_dirs if classify_lp_from_dirname(d.name) == lp]

    chosen = pick_newest(candidates)
    if chosen is None:
        return CompileResult(lp=lp, status="NA", log_path=None, errors=[], chosen_dir=None)

    log_path = chosen / "test.log"
    lines = safe_read_lines(log_path)

    if second_last_nonempty_line_contains(lines, DB_OK_STR):
        return CompileResult(lp=lp, status="PASS",
                             log_path=log_path if log_path.exists() else None,
                             errors=[], chosen_dir=chosen.name)

    errs = extract_compile_errors(lines)
    return CompileResult(lp=lp, status="FAIL",
                         log_path=log_path if log_path.exists() else None,
                         errors=errs, chosen_dir=chosen.name)


def find_test_dirs(sim_dir: Path) -> List[Path]:
    """
    Test directories:
      - under sim/
      - not starting with compile_dw_
      - contains 'vtb' in name (based on your environment)
    """
    if not sim_dir.is_dir():
        return []
    out: List[Path] = []
    for p in sim_dir.iterdir():
        if not p.is_dir():
            continue
        if p.name.startswith("compile_dw_"):
            continue
        if "vtb" not in p.name.lower():
            continue
        out.append(p)
    return sorted(out, key=lambda x: x.name)


def parse_test_results(sim_dir: Path) -> List[TestResult]:
    results: List[TestResult] = []
    for tdir in find_test_dirs(sim_dir):
        log_path = tdir / "test.log"
        lines = safe_read_lines(log_path)
        uerr, ufat = count_uvm(lines)
        status = "PASS" if (uerr == 0 and ufat == 0) else "FAIL"
        results.append(TestResult(
            test_dir=tdir.name,
            status=status,
            uvm_error_count=uerr,
            uvm_fatal_count=ufat,
            log_path=log_path if log_path.exists() else None,
        ))
    return results


def is_config_compile_clean(vdut: CompileResult, vip: CompileResult) -> bool:
    return vdut.status == "PASS" and vip.status == "PASS"


# ----------------- Excel Writer (matches your screenshot layout) -----------------
def make_excel_report(
    out_path: Path,
    reg_root: Path,
    configs_data: Dict[str, Dict],
    today: str,
    include_per_test: bool,
) -> None:
    wb = Workbook()
    ws = wb.active
    ws.title = "Summary"

    # Styles
    header_font = Font(bold=True)
    center = Alignment(vertical="center", horizontal="center", wrap_text=True)
    left = Alignment(vertical="center", horizontal="left", wrap_text=True)

    thin = Side(style="thin")
    border = Border(left=thin, right=thin, top=thin, bottom=thin)

    pass_fill = PatternFill("solid", fgColor="C6EFCE")  # light green
    fail_fill = PatternFill("solid", fgColor="FFC7CE")  # light red
    na_fill = PatternFill("solid", fgColor="E7E6E6")    # light grey

    def fill_for_status(s: str) -> PatternFill:
        s_up = (s or "").upper()
        if "PASS" in s_up:
            return pass_fill
        if "FAIL" in s_up:
            return fail_fill
        return na_fill

    # Header row
    headers = ["CONFIG NAME", "LP", "Compilation /Run status", "Todays Date"]
    ws.append(headers)
    for c in range(1, 5):
        cell = ws.cell(row=1, column=c)
        cell.font = header_font
        cell.alignment = center
        cell.border = border

    # Optional: top meta info (commented out; enable if you want)
    # ws.insert_rows(1, amount=2)  # would shift header; keeping simple per your screenshot

    row = 2

    # Write each config block
    for cfg_name in sorted(configs_data.keys()):
        cfg_block_start = row

        for lp in ["VDUT", "VIP"]:
            lp_block_start = row

            comp: CompileResult = configs_data[cfg_name]["compile"][lp]
            run_summary: str = configs_data[cfg_name]["run"][lp]["summary"]
            per_test_lines: List[str] = configs_data[cfg_name]["run"][lp]["per_test"]

            # Row 1: Compilation Status
            comp_text = f"Compilation Status : {comp.status}"
            extras = []
            if comp.chosen_dir:
                extras.append(f"dir={comp.chosen_dir}")
            if comp.log_path:
                extras.append(f"log={comp.log_path}")
            if extras:
                comp_text += "  (" + ", ".join(extras) + ")"

            # If FAIL, append first few errors
            if comp.status == "FAIL" and comp.errors:
                comp_text += "\nErrors: " + "; ".join(comp.errors[:5])
                if len(comp.errors) > 5:
                    comp_text += " ..."

            ws.append([cfg_name, lp, comp_text, today])
            ws.cell(row=row, column=3).fill = fill_for_status(comp.status)
            row += 1

            # Row 2: Run Results
            run_text = f"Run Results : {run_summary}"
            ws.append(["", "", run_text, today])
            # If run summary implies FAIL/PASS, color it accordingly
            ws.cell(row=row, column=3).fill = fill_for_status(run_summary)
            row += 1

            # Optional per-test rows (indented in status column)
            if include_per_test and per_test_lines:
                for line in per_test_lines:
                    ws.append(["", "", "  " + line, today])
                    # If line includes FAIL/PASS, color lightly
                    ws.cell(row=row, column=3).fill = fill_for_status(line)
                    row += 1

            # Merge LP column for that LP block
            ws.merge_cells(start_row=lp_block_start, start_column=2, end_row=row - 1, end_column=2)

        # Merge CONFIG NAME column for full config block
        ws.merge_cells(start_row=cfg_block_start, start_column=1, end_row=row - 1, end_column=1)

        # Add a blank separator row between configs (like visual spacing)
        ws.append(["", "", "", ""])
        row += 1

    # Apply borders + alignment
    max_row = ws.max_row
    for r in range(1, max_row + 1):
        for c in range(1, 5):
            cell = ws.cell(row=r, column=c)
            cell.border = border
            if r == 1:
                continue
            if c in (1, 2, 4):
                cell.alignment = center
            else:
                cell.alignment = left

    # Column widths similar to your screenshot
    ws.column_dimensions["A"].width = 25
    ws.column_dimensions["B"].width = 10
    ws.column_dimensions["C"].width = 80
    ws.column_dimensions["D"].width = 14

    out_path.parent.mkdir(parents=True, exist_ok=True)
    wb.save(out_path)


# ----------------- Main orchestrator -----------------
def main() -> None:
    ap = argparse.ArgumentParser(description="Generate formatted Excel summary for regression configs containing 'uio'.")
    ap.add_argument("regression_path", help="Regression root directory path")
    ap.add_argument(
        "-o", "--out",
        default=None,
        help="Output Excel file path (default: <regression_path>/regression_summary.xlsx)"
    )
    ap.add_argument(
        "--no-per-test",
        action="store_true",
        help="Do not include per-test breakdown lines in Excel; only show totals."
    )
    args = ap.parse_args()

    reg_root = Path(args.regression_path).resolve()
    out_path = Path(args.out).resolve() if args.out else (reg_root / "regression_summary.xlsx")
    today = dt.date.today().isoformat()

    configs = discover_configs(reg_root)
    if not configs:
        raise SystemExit(
            f"No config dirs found under {reg_root}.\n"
            f"Expected: subdirs whose name contains 'uio' and which have a 'sim/' directory."
        )

    # Build data model for Excel writer
    configs_data: Dict[str, Dict] = {}

    for cfg_dir in configs:
        cfg_name = cfg_dir.name
        sim_dir = cfg_dir / "sim"

        vdut_comp = compile_status_for_lp(sim_dir, "VDUT")
        vip_comp = compile_status_for_lp(sim_dir, "VIP")

        compile_clean = is_config_compile_clean(vdut_comp, vip_comp)

        run_data = {
            "VDUT": {"summary": "SKIPPED (compile not clean)", "per_test": []},
            "VIP":  {"summary": "SKIPPED (compile not clean)", "per_test": []},
        }

        if compile_clean:
            tests = parse_test_results(sim_dir)

            total = len(tests)
            passed = sum(1 for t in tests if t.status == "PASS")
            failed = sum(1 for t in tests if t.status == "FAIL")

            # Run summary applies at config-level; we show it under both VDUT and VIP to match your table template
            summary = f"TOTAL={total} PASS={passed} FAIL={failed}"
            per_test_lines = []
            for t in tests:
                per_test_lines.append(
                    f"{t.test_dir} => {t.status} (UVM_ERROR={t.uvm_error_count}, UVM_FATAL={t.uvm_fatal_count})"
                    + (f" | log={t.log_path}" if t.log_path else "")
                )

            run_data["VDUT"]["summary"] = summary
            run_data["VIP"]["summary"] = summary
            run_data["VDUT"]["per_test"] = per_test_lines
            run_data["VIP"]["per_test"] = per_test_lines

        configs_data[cfg_name] = {
            "compile": {"VDUT": vdut_comp, "VIP": vip_comp},
            "run": run_data,
        }

    make_excel_report(
        out_path=out_path,
        reg_root=reg_root,
        configs_data=configs_data,
        today=today,
        include_per_test=(not args.no_per_test),
    )

    print(f"Excel report generated: {out_path}")
    print(f"Configs detected (contain 'uio'): {len(configs)}")


if __name__ == "__main__":
    main()
