#!/usr/bin/env python3
"""
PCIe Regression Summary -> Excel (formatted like screenshot)

Detection rules (as per your latest requirements):
- Config directory can be anything, but config dir name contains 'uio' (case-insensitive)
- Config dir must have <config>/sim/
- Under <config>/sim/:
  - compile directories begin with 'compile_dw_'
    - VDUT compile dir contains 'vdut' in dir name
    - VIP  compile dir contains 'vip'  in dir name
    - compile result: <compile_dir>/test.log
        PASS if second-last non-empty line contains: "database successfully generated"
        FAIL otherwise; extract errors by matching "Error-["
  - if BOTH VDUT and VIP compile PASS => run starts
  - test directories:
      - not starting with 'compile_dw_'
      - name contains 'vtb' (case-insensitive)
      - each has test.log
      - FAIL if log contains UVM_ERROR or UVM_FATAL (counted); else PASS

Excel output layout (matches screenshot):
CONFIG NAME | LP  | Compilation/Run status | Todays Date
-------------------------------------------------------
cfgX        |VDUT | Compilation Status : PASS/FAIL ...
           |     | Run Results : TOTAL=.. PASS=.. FAIL=.. (and optionally per-test)
           |VIP  | Compilation Status : ...
           |     | Run Results : ...

Usage:
  python3 regress_summary_excel_uio.py /path/to/regression
  python3 regress_summary_excel_uio.py /path/to/regression -o /path/to/out.xlsx
  python3 regress_summary_excel_uio.py /path/to/regression --no-per-test
"""

from __future__ import annotations

import argparse
import datetime as dt
import re
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Tuple, Dict

from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side


# ---------- Parsing patterns ----------
DB_OK_STR = "database successfully generated"

# IMPORTANT: '[' must be escaped
ERR_PATTERN = re.compile(r"Error-\[", re.IGNORECASE)

UVM_ERR_PATTERN = re.compile(r"\bUVM_ERROR\b")
UVM_FATAL_PATTERN = re.compile(r"\bUVM_FATAL\b")


@dataclass
class CompileResult:
    lp: str
    status: str              # PASS/FAIL/NA
    log_path: Optional[Path]
    errors: List[str]
    chosen_dir: Optional[str]


@dataclass
class TestResult:
    test_dir: str
    status: str              # PASS/FAIL
    uvm_error_count: int
    uvm_fatal_count: int
    uvm_messages: List[str]  # actual lines
    log_path: Optional[Path]


# ----------------- Log helpers -----------------
def safe_read_lines(log_path: Path, max_bytes: int = 10_000_000) -> List[str]:
    try:
        with log_path.open("rb") as f:
            data = f.read(max_bytes + 1)
        if len(data) > max_bytes:
            data = data[:max_bytes]
        return data.decode(errors="replace").splitlines()
    except (FileNotFoundError, OSError):
        return []


def second_last_nonempty_line_contains(lines: List[str], needle: str) -> bool:
    trimmed = [l for l in lines if l.strip()]
    if not trimmed:
        return False
    if len(trimmed) < 2:
        return needle in trimmed[-1]
    return needle in trimmed[-2]


def extract_compile_errors(lines: List[str], max_lines: int = 30) -> List[str]:
    errs = [l.strip() for l in lines if ERR_PATTERN.search(l)]
    seen = set()
    uniq: List[str] = []
    for e in errs:
        if e not in seen:
            uniq.append(e)
            seen.add(e)
        if len(uniq) >= max_lines:
            break
    return uniq


def count_uvm(lines: List[str]) -> Tuple[int, int]:
    err_cnt = sum(1 for l in lines if UVM_ERR_PATTERN.search(l))
    fatal_cnt = sum(1 for l in lines if UVM_FATAL_PATTERN.search(l))
    return err_cnt, fatal_cnt


def extract_uvm_messages(lines: List[str], max_lines: int = 50) -> List[str]:
    """
    Extract actual UVM_ERROR / UVM_FATAL lines (limited to keep Excel readable).
    """
    msgs: List[str] = []
    for line in lines:
        if "UVM_ERROR" in line or "UVM_FATAL" in line:
            msgs.append(line.strip())
        if len(msgs) >= max_lines:
            break
    return msgs


# ----------------- Discover regression structure -----------------
def discover_configs(reg_root: Path) -> List[Path]:
    """
    Config dirs:
    - immediate subdirs under regression root
    - dir name contains 'uio'
    - contains sim/
    """
    if not reg_root.is_dir():
        return []
    configs = []
    for p in reg_root.iterdir():
        if p.is_dir() and ("uio" in p.name.lower()) and (p / "sim").is_dir():
            configs.append(p)
    return sorted(configs, key=lambda x: x.name)


def find_compile_dirs(sim_dir: Path) -> List[Path]:
    if not sim_dir.is_dir():
        return []
    return [p for p in sim_dir.iterdir() if p.is_dir() and p.name.startswith("compile_dw_")]


def classify_lp_from_dirname(name: str) -> Optional[str]:
    n = name.lower()
    if "vdut" in n:
        return "VDUT"
    if "vip" in n:
        return "VIP"
    return None


def pick_newest(paths: List[Path]) -> Optional[Path]:
    return max(paths, key=lambda p: p.stat().st_mtime) if paths else None


def compile_status_for_lp(sim_dir: Path, lp: str) -> CompileResult:
    compile_dirs = find_compile_dirs(sim_dir)
    candidates = [d for d in compile_dirs if classify_lp_from_dirname(d.name) == lp]
    chosen = pick_newest(candidates)

    if chosen is None:
        return CompileResult(lp=lp, status="NA", log_path=None, errors=[], chosen_dir=None)

    log_path = chosen / "test.log"
    lines = safe_read_lines(log_path)

    if second_last_nonempty_line_contains(lines, DB_OK_STR):
        return CompileResult(lp=lp, status="PASS",
                             log_path=log_path if log_path.exists() else None,
                             errors=[], chosen_dir=chosen.name)

    errs = extract_compile_errors(lines)
    return CompileResult(lp=lp, status="FAIL",
                         log_path=log_path if log_path.exists() else None,
                         errors=errs, chosen_dir=chosen.name)


def find_test_dirs(sim_dir: Path) -> List[Path]:
    """
    Test dirs:
    - under sim/
    - not starting with compile_dw_
    - contains 'vtb' in name
    """
    if not sim_dir.is_dir():
        return []
    out = []
    for p in sim_dir.iterdir():
        if not p.is_dir():
            continue
        if p.name.startswith("compile_dw_"):
            continue
        if "vtb" not in p.name.lower():
            continue
        out.append(p)
    return sorted(out, key=lambda x: x.name)


def parse_test_results(sim_dir: Path) -> List[TestResult]:
    results: List[TestResult] = []
    for tdir in find_test_dirs(sim_dir):
        log_path = tdir / "test.log"
        lines = safe_read_lines(log_path)
        uerr, ufat = count_uvm(lines)
        msgs = extract_uvm_messages(lines)
        status = "PASS" if (uerr == 0 and ufat == 0) else "FAIL"
        results.append(TestResult(
            test_dir=tdir.name,
            status=status,
            uvm_error_count=uerr,
            uvm_fatal_count=ufat,
            uvm_messages=msgs,
            log_path=log_path if log_path.exists() else None,
        ))
    return results


def is_config_compile_clean(vdut: CompileResult, vip: CompileResult) -> bool:
    return (vdut.status == "PASS") and (vip.status == "PASS")


# ----------------- Cell builders (Todays Date cell contains date + details) -----------------
def build_compilation_cell(today: str, comp: CompileResult) -> str:
    """
    Single cell content:
      <date>
      Compilation: PASS/FAIL/NA
      Info: dir=..., log=...
      Errors:
        1) Error-[...]
    """
    lines: List[str] = [today, f"Compilation: {comp.status}"]

    info = []
    if comp.chosen_dir:
        info.append(f"dir={comp.chosen_dir}")
    if comp.log_path:
        info.append(f"log={comp.log_path}")
    if info:
        lines.append("Info: " + ", ".join(info))

    if comp.status == "FAIL":
        if comp.errors:
            lines.append("Errors:")
            for i, e in enumerate(comp.errors[:10], start=1):
                lines.append(f"  {i}) {e}")
        else:
            lines.append("Errors: (no Error-[ lines found)")

    return "\n".join(lines)


def build_run_cell(today: str, run_summary: str, tests: List[TestResult]) -> str:
    """
    Single cell content:
      <date>
      Run Summary: TOTAL=.. PASS=.. FAIL=..
      Failures:
        1) test_xxx
            1. UVM_ERROR ...
            2. UVM_FATAL ...
    """
    lines: List[str] = [today, f"Run Summary: {run_summary}"]

    if run_summary.startswith("SKIPPED") or run_summary.startswith("NA"):
        return "\n".join(lines)

    failing = [t for t in tests if t.status == "FAIL"]
    if not failing:
        return "\n".join(lines)

    lines.append("Failures:")
    fail_idx = 1
    for t in failing:
        lines.append(f"{fail_idx}) {t.test_dir} (log={t.log_path if t.log_path else 'NA'})")
        if t.uvm_messages:
            msg_idx = 1
            for msg in t.uvm_messages:
                lines.append(f"    {msg_idx}. {msg}")
                msg_idx += 1
        else:
            lines.append("    1. (No UVM_ERROR/UVM_FATAL lines found)")
        fail_idx += 1

    return "\n".join(lines)


# ----------------- Excel writer (your requested format) -----------------
def write_excel(out_path: Path, configs_data: Dict[str, Dict], today: str) -> None:
    wb = Workbook()
    ws = wb.active
    ws.title = "Summary"

    # Styles
    header_font = Font(bold=True)
    center = Alignment(vertical="center", horizontal="center", wrap_text=True)
    left_top = Alignment(vertical="top", horizontal="left", wrap_text=True)

    thin = Side(style="thin")
    border = Border(left=thin, right=thin, top=thin, bottom=thin)

    pass_fill = PatternFill("solid", fgColor="C6EFCE")
    fail_fill = PatternFill("solid", fgColor="FFC7CE")
    na_fill = PatternFill("solid", fgColor="E7E6E6")

    def fill_for_cell_text(cell_text: str) -> PatternFill:
        t = (cell_text or "").upper()
        if "COMPILATION: PASS" in t:
            return pass_fill
        if "COMPILATION: FAIL" in t:
            return fail_fill
        if "RUN SUMMARY: TOTAL=" in t and " FAIL=0" in t:
            return pass_fill
        if "FAILURES:" in t:
            return fail_fill
        if "SKIPPED" in t or "NA" in t:
            return na_fill
        return na_fill

    # Header row
    ws.append(["CONFIG NAME", "LP", "Status", "Todays Date"])
    for c in range(1, 5):
        cell = ws.cell(row=1, column=c)
        cell.font = header_font
        cell.alignment = center
        cell.border = border

    row = 2

    for cfg_name in sorted(configs_data.keys()):
        cfg_start = row

        for lp in ["VDUT", "VIP"]:
            lp_start = row

            # Compilation row
            comp_text = configs_data[cfg_name]["comp_cells"][lp]
            ws.append([cfg_name, lp, "Compilation Status", comp_text])
            ws.cell(row=row, column=4).fill = fill_for_cell_text(comp_text)
            row += 1

            # Run row
            run_text = configs_data[cfg_name]["run_cells"][lp]
            ws.append(["", "", "Run Results", run_text])
            ws.cell(row=row, column=4).fill = fill_for_cell_text(run_text)
            row += 1

            # Merge LP across 2 rows
            ws.merge_cells(start_row=lp_start, start_column=2, end_row=row - 1, end_column=2)

        # Merge CONFIG across 4 rows
        ws.merge_cells(start_row=cfg_start, start_column=1, end_row=row - 1, end_column=1)

        # Optional blank separator
        ws.append(["", "", "", ""])
        row += 1

    # Apply borders and alignment to all cells
    for r in range(1, ws.max_row + 1):
        for c in range(1, 5):
            cell = ws.cell(row=r, column=c)
            cell.border = border
            if r == 1:
                continue
            if c in (1, 2, 3):
                cell.alignment = center
            else:
                cell.alignment = left_top

    # Column widths
    ws.column_dimensions["A"].width = 26
    ws.column_dimensions["B"].width = 10
    ws.column_dimensions["C"].width = 22
    ws.column_dimensions["D"].width = 95

    out_path.parent.mkdir(parents=True, exist_ok=True)
    wb.save(out_path)


def main() -> None:
    ap = argparse.ArgumentParser(description="Generate formatted Excel summary (date + details in same cell).")
    ap.add_argument("regression_path", help="Regression root directory path")
    ap.add_argument("-o", "--out", default=None,
                    help="Output Excel file path (default: <regression_path>/regression_summary.xlsx)")
    args = ap.parse_args()

    reg_root = Path(args.regression_path).resolve()
    out_path = Path(args.out).resolve() if args.out else (reg_root / "regression_summary.xlsx")
    today = dt.date.today().isoformat()

    configs = discover_configs(reg_root)
    if not configs:
        raise SystemExit(
            f"No config dirs found under {reg_root}. Expected subdirs containing 'uio' and having sim/."
        )

    configs_data: Dict[str, Dict] = {}

    for cfg_dir in configs:
        cfg_name = cfg_dir.name
        sim_dir = cfg_dir / "sim"

        vdut_comp = compile_status_for_lp(sim_dir, "VDUT")
        vip_comp = compile_status_for_lp(sim_dir, "VIP")

        if is_config_compile_clean(vdut_comp, vip_comp):
            tests = parse_test_results(sim_dir)
            total = len(tests)
            passed = sum(1 for t in tests if t.status == "PASS")
            failed = sum(1 for t in tests if t.status == "FAIL")
            run_summary = f"TOTAL={total} PASS={passed} FAIL={failed}"
        else:
            tests = []
            run_summary = "SKIPPED (compile not clean)"

        comp_cells = {
            "VDUT": build_compilation_cell(today, vdut_comp),
            "VIP": build_compilation_cell(today, vip_comp),
        }
        run_cells = {
            # show same run summary under both LP blocks (keeps 4-row template consistent)
            "VDUT": build_run_cell(today, run_summary, tests),
            "VIP": build_run_cell(today, run_summary, tests),
        }

        configs_data[cfg_name] = {"comp_cells": comp_cells, "run_cells": run_cells}

    write_excel(out_path, configs_data, today)
    print(f"Excel report generated: {out_path}")
    print(f"Configs detected: {len(configs)}")


if __name__ == "__main__":
    main()
